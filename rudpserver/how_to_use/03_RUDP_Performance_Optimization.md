# RUDP ì„œë²„ ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ì„±ëŠ¥ ëª©í‘œ ë° í˜„í™©](#ì„±ëŠ¥-ëª©í‘œ-ë°-í˜„í™©)
2. [SIMD í•˜ë“œì›¨ì–´ ê°€ì†](#simd-í•˜ë“œì›¨ì–´-ê°€ì†)
3. [ì œë¡œì¹´í”¼ I/O ìµœì í™”](#ì œë¡œì¹´í”¼-io-ìµœì í™”)
4. [ì ì‘í˜• í˜¼ì¡ ì œì–´](#ì ì‘í˜•-í˜¼ì¡-ì œì–´)
5. [ë©”ëª¨ë¦¬ ìµœì í™” ì „ëµ](#ë©”ëª¨ë¦¬-ìµœì í™”-ì „ëµ)
6. [ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§](#ì„±ëŠ¥-ëª¨ë‹ˆí„°ë§)

## ğŸ¯ ì„±ëŠ¥ ëª©í‘œ ë° í˜„í™©

### ëª©í‘œ ì„±ëŠ¥ ì§€í‘œ
```
RUDP Server Performance Targets:
â”œâ”€â”€ ì²˜ë¦¬ëŸ‰: 20,000+ msg/sec
â”œâ”€â”€ ì§€ì—°ì‹œê°„: <0.5ms p99
â”œâ”€â”€ ë©”ëª¨ë¦¬: 8-10MB for 1000 connections
â”œâ”€â”€ CPU íš¨ìœ¨: ë‹¨ì¼ ì½”ì–´ ìµœì í™”
â”œâ”€â”€ íŒ¨í‚· ì†ì‹¤ë¥ : <0.1%
â””â”€â”€ ì¬ì „ì†¡ ë¹„ìœ¨: <2%
```

### í˜„ì¬ ìµœì í™” ì„œë¹„ìŠ¤ (16ê°œ)
```
Performance Services
â”œâ”€â”€ SIMD Packet Processor (AVX2/SSE4.2)
â”œâ”€â”€ Zero-Copy I/O Engine
â”œâ”€â”€ Adaptive Congestion Control
â”œâ”€â”€ Enhanced Memory Pool (5-tier)
â”œâ”€â”€ Lock-Free Ring Buffer
â”œâ”€â”€ NUMA-Aware Allocation
â”œâ”€â”€ CPU Affinity Manager
â”œâ”€â”€ Network Interrupt Coalescing
â”œâ”€â”€ Batch Processing Engine
â”œâ”€â”€ Connection Pool Manager
â”œâ”€â”€ Latency Tracker
â”œâ”€â”€ Throughput Monitor
â”œâ”€â”€ Cache Line Optimizer
â”œâ”€â”€ Prefetch Controller
â”œâ”€â”€ Branch Predictor Optimizer
â””â”€â”€ Memory Bandwidth Manager
```

## âš¡ SIMD í•˜ë“œì›¨ì–´ ê°€ì†

### 1. SIMD íŒ¨í‚· í”„ë¡œì„¸ì„œ êµ¬í˜„

```rust
// service/simd_packet_processor.rs
use std::arch::x86_64::*;
use crate::protocol::rudp::RudpPacket;

pub struct SimdPacketProcessor {
    simd_features: SimdFeatures,
    batch_buffer: Vec<RudpPacket>,
}

#[derive(Debug)]
pub struct SimdFeatures {
    pub avx2: bool,
    pub avx512: bool,
    pub sse42: bool,
}

impl SimdPacketProcessor {
    pub fn new() -> Self {
        Self {
            simd_features: Self::detect_simd_features(),
            batch_buffer: Vec::with_capacity(32),
        }
    }
    
    /// SIMD ê¸°ëŠ¥ ê°ì§€
    fn detect_simd_features() -> SimdFeatures {
        SimdFeatures {
            avx2: is_x86_feature_detected!("avx2"),
            avx512: is_x86_feature_detected!("avx512f"),
            sse42: is_x86_feature_detected!("sse4.2"),
        }
    }
    
    /// ë°°ì¹˜ íŒ¨í‚· ì²´í¬ì„¬ ê³„ì‚° (AVX2)
    pub fn calculate_checksums_batch(&self, packets: &[RudpPacket]) -> Vec<u32> {
        if self.simd_features.avx2 {
            self.calculate_checksums_avx2(packets)
        } else if self.simd_features.sse42 {
            self.calculate_checksums_sse42(packets)
        } else {
            self.calculate_checksums_scalar(packets)
        }
    }
    
    /// AVX2ë¥¼ ì´ìš©í•œ ë³‘ë ¬ ì²´í¬ì„¬ ê³„ì‚°
    fn calculate_checksums_avx2(&self, packets: &[RudpPacket]) -> Vec<u32> {
        let mut checksums = Vec::with_capacity(packets.len());
        
        unsafe {
            // 8ê°œì”© ë³‘ë ¬ ì²˜ë¦¬
            for chunk in packets.chunks(8) {
                let mut data_ptrs = [std::ptr::null(); 8];
                let mut lengths = [0u32; 8];
                
                // í¬ì¸í„°ì™€ ê¸¸ì´ ì¤€ë¹„
                for (i, packet) in chunk.iter().enumerate() {
                    data_ptrs[i] = packet.payload.as_ptr();
                    lengths[i] = packet.payload.len() as u32;
                }
                
                // AVX2 ë ˆì§€ìŠ¤í„°ì— ê¸¸ì´ ë¡œë“œ
                let length_vec = _mm256_loadu_si256(lengths.as_ptr() as *const __m256i);
                
                // ê° íŒ¨í‚·ì˜ ì²´í¬ì„¬ ê³„ì‚° (ë³‘ë ¬)
                for i in 0..chunk.len() {
                    let checksum = self.fast_checksum_avx2(data_ptrs[i], lengths[i] as usize);
                    checksums.push(checksum);
                }
            }
        }
        
        checksums
    }
    
    /// AVX2 ìµœì í™”ëœ ì²´í¬ì„¬ ê³„ì‚°
    unsafe fn fast_checksum_avx2(&self, data: *const u8, len: usize) -> u32 {
        let mut checksum = 0u32;
        let mut pos = 0;
        
        // 32ë°”ì´íŠ¸ì”© ë³‘ë ¬ ì²˜ë¦¬
        while pos + 32 <= len {
            let chunk = _mm256_loadu_si256(data.add(pos) as *const __m256i);
            
            // ë°”ì´íŠ¸ë¥¼ 32ë¹„íŠ¸ ì •ìˆ˜ë¡œ í™•ì¥í•˜ì—¬ í•©ê³„ ê³„ì‚°
            let lo = _mm256_unpacklo_epi8(chunk, _mm256_setzero_si256());
            let hi = _mm256_unpackhi_epi8(chunk, _mm256_setzero_si256());
            
            let sum_lo = _mm256_sad_epu8(lo, _mm256_setzero_si256());
            let sum_hi = _mm256_sad_epu8(hi, _mm256_setzero_si256());
            
            // ìˆ˜í‰ í•©ê³„
            let total = _mm256_add_epi64(sum_lo, sum_hi);
            let sum_128 = _mm_add_epi64(
                _mm256_extracti128_si256(total, 0),
                _mm256_extracti128_si256(total, 1)
            );
            
            checksum = checksum.wrapping_add(_mm_extract_epi64(sum_128, 0) as u32);
            checksum = checksum.wrapping_add(_mm_extract_epi64(sum_128, 1) as u32);
            
            pos += 32;
        }
        
        // ë‚˜ë¨¸ì§€ ë°”ì´íŠ¸ ì²˜ë¦¬
        while pos < len {
            checksum = checksum.wrapping_add(*data.add(pos) as u32);
            pos += 1;
        }
        
        checksum
    }
    
    /// SSE4.2 ì²´í¬ì„¬ ê³„ì‚°
    fn calculate_checksums_sse42(&self, packets: &[RudpPacket]) -> Vec<u32> {
        let mut checksums = Vec::with_capacity(packets.len());
        
        unsafe {
            for packet in packets {
                let checksum = self.fast_checksum_sse42(
                    packet.payload.as_ptr(),
                    packet.payload.len()
                );
                checksums.push(checksum);
            }
        }
        
        checksums
    }
    
    /// SSE4.2 ìµœì í™”ëœ ì²´í¬ì„¬
    unsafe fn fast_checksum_sse42(&self, data: *const u8, len: usize) -> u32 {
        let mut checksum = 0u32;
        let mut pos = 0;
        
        // 16ë°”ì´íŠ¸ì”© ì²˜ë¦¬
        while pos + 16 <= len {
            let chunk = _mm_loadu_si128(data.add(pos) as *const __m128i);
            let sad = _mm_sad_epu8(chunk, _mm_setzero_si128());
            
            checksum = checksum.wrapping_add(_mm_extract_epi16(sad, 0) as u32);
            checksum = checksum.wrapping_add(_mm_extract_epi16(sad, 4) as u32);
            
            pos += 16;
        }
        
        // ë‚˜ë¨¸ì§€ ì²˜ë¦¬
        while pos < len {
            checksum = checksum.wrapping_add(*data.add(pos) as u32);
            pos += 1;
        }
        
        checksum
    }
    
    /// ìŠ¤ì¹¼ë¼ ì²´í¬ì„¬ (fallback)
    fn calculate_checksums_scalar(&self, packets: &[RudpPacket]) -> Vec<u32> {
        packets.iter().map(|packet| {
            packet.payload.iter().map(|&b| b as u32).sum()
        }).collect()
    }
}
```

### 2. SIMD ë©”ëª¨ë¦¬ ë¹„êµ ìµœì í™”

```rust
// service/simd_memory_ops.rs
use std::arch::x86_64::*;

pub struct SimdMemoryOps;

impl SimdMemoryOps {
    /// AVX2 ë©”ëª¨ë¦¬ ë¹„êµ (ìµœëŒ€ 256ë¹„íŠ¸)
    pub unsafe fn memory_compare_avx2(a: &[u8], b: &[u8]) -> bool {
        if a.len() != b.len() {
            return false;
        }
        
        let len = a.len();
        let mut pos = 0;
        
        // 32ë°”ì´íŠ¸ì”© ë¹„êµ
        while pos + 32 <= len {
            let chunk_a = _mm256_loadu_si256(a.as_ptr().add(pos) as *const __m256i);
            let chunk_b = _mm256_loadu_si256(b.as_ptr().add(pos) as *const __m256i);
            
            let cmp = _mm256_cmpeq_epi8(chunk_a, chunk_b);
            let mask = _mm256_movemask_epi8(cmp);
            
            if mask != -1 { // 0xFFFFFFFF
                return false;
            }
            
            pos += 32;
        }
        
        // ë‚˜ë¨¸ì§€ ë°”ì´íŠ¸ ë¹„êµ
        for i in pos..len {
            if a[i] != b[i] {
                return false;
            }
        }
        
        true
    }
    
    /// SIMD ë©”ëª¨ë¦¬ ë³µì‚¬ ìµœì í™”
    pub unsafe fn fast_memcpy(dest: *mut u8, src: *const u8, len: usize) {
        let mut pos = 0;
        
        // 32ë°”ì´íŠ¸ì”© ë³µì‚¬ (AVX2)
        if is_x86_feature_detected!("avx2") {
            while pos + 32 <= len {
                let data = _mm256_loadu_si256(src.add(pos) as *const __m256i);
                _mm256_storeu_si256(dest.add(pos) as *mut __m256i, data);
                pos += 32;
            }
        }
        
        // 16ë°”ì´íŠ¸ì”© ë³µì‚¬ (SSE2)
        while pos + 16 <= len {
            let data = _mm_loadu_si128(src.add(pos) as *const __m128i);
            _mm_storeu_si128(dest.add(pos) as *mut __m128i, data);
            pos += 16;
        }
        
        // ë‚˜ë¨¸ì§€ ë°”ì´íŠ¸ ë³µì‚¬
        while pos < len {
            *dest.add(pos) = *src.add(pos);
            pos += 1;
        }
    }
}
```

## ğŸ”„ ì œë¡œì¹´í”¼ I/O ìµœì í™”

### 1. ì œë¡œì¹´í”¼ ë²„í¼ ì‹œìŠ¤í…œ

```rust
// service/zero_copy_io.rs
use std::sync::Arc;
use std::ptr;
use std::slice;

pub struct ZeroCopyBuffer {
    data: *mut u8,
    capacity: usize,
    len: usize,
    shared: Arc<BufferMetadata>,
}

struct BufferMetadata {
    ref_count: std::sync::atomic::AtomicUsize,
    original_ptr: *mut u8,
    original_capacity: usize,
}

unsafe impl Send for ZeroCopyBuffer {}
unsafe impl Sync for ZeroCopyBuffer {}

impl ZeroCopyBuffer {
    /// ë©”ëª¨ë¦¬ ì§ì ‘ í• ë‹¹
    pub fn new(capacity: usize) -> Result<Self, std::io::Error> {
        let layout = std::alloc::Layout::from_size_align(capacity, 64)
            .map_err(|_| std::io::Error::new(std::io::ErrorKind::InvalidInput, "Invalid layout"))?;
            
        let data = unsafe { std::alloc::alloc(layout) };
        
        if data.is_null() {
            return Err(std::io::Error::new(
                std::io::ErrorKind::OutOfMemory, 
                "Failed to allocate buffer"
            ));
        }
        
        Ok(Self {
            data,
            capacity,
            len: 0,
            shared: Arc::new(BufferMetadata {
                ref_count: std::sync::atomic::AtomicUsize::new(1),
                original_ptr: data,
                original_capacity: capacity,
            }),
        })
    }
    
    /// ë‹¤ë¥¸ ë²„í¼ì™€ ë©”ëª¨ë¦¬ ê³µìœ 
    pub fn share_slice(&self, offset: usize, len: usize) -> Result<Self, std::io::Error> {
        if offset + len > self.len {
            return Err(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Slice out of bounds"
            ));
        }
        
        self.shared.ref_count.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        
        Ok(Self {
            data: unsafe { self.data.add(offset) },
            capacity: len,
            len,
            shared: self.shared.clone(),
        })
    }
    
    /// ì§ì ‘ ë©”ëª¨ë¦¬ ì•¡ì„¸ìŠ¤ (ì œë¡œì¹´í”¼)
    pub fn as_slice(&self) -> &[u8] {
        unsafe { slice::from_raw_parts(self.data, self.len) }
    }
    
    pub fn as_mut_slice(&mut self) -> &mut [u8] {
        unsafe { slice::from_raw_parts_mut(self.data, self.len) }
    }
    
    /// íŠ¹ì • ìœ„ì¹˜ì—ì„œ ë°ì´í„° ì½ê¸°
    pub fn read_u32_at(&self, offset: usize) -> Result<u32, std::io::Error> {
        if offset + 4 > self.len {
            return Err(std::io::Error::new(
                std::io::ErrorKind::UnexpectedEof,
                "Read out of bounds"
            ));
        }
        
        let ptr = unsafe { self.data.add(offset) as *const u32 };
        Ok(unsafe { ptr.read_unaligned() })
    }
    
    /// íŠ¹ì • ìœ„ì¹˜ì— ë°ì´í„° ì“°ê¸°
    pub fn write_u32_at(&mut self, offset: usize, value: u32) -> Result<(), std::io::Error> {
        if offset + 4 > self.capacity {
            return Err(std::io::Error::new(
                std::io::ErrorKind::WriteZero,
                "Write out of bounds"
            ));
        }
        
        let ptr = unsafe { self.data.add(offset) as *mut u32 };
        unsafe { ptr.write_unaligned(value) };
        
        self.len = self.len.max(offset + 4);
        Ok(())
    }
    
    /// ë²¡í„°í™”ëœ I/O (scatter-gather)
    pub fn write_vectored(&mut self, bufs: &[&[u8]]) -> Result<usize, std::io::Error> {
        let mut total_written = 0;
        let mut pos = self.len;
        
        for buf in bufs {
            if pos + buf.len() > self.capacity {
                break;
            }
            
            unsafe {
                ptr::copy_nonoverlapping(
                    buf.as_ptr(),
                    self.data.add(pos),
                    buf.len()
                );
            }
            
            pos += buf.len();
            total_written += buf.len();
        }
        
        self.len = pos;
        Ok(total_written)
    }
}

impl Drop for ZeroCopyBuffer {
    fn drop(&mut self) {
        let prev_count = self.shared.ref_count.fetch_sub(1, std::sync::atomic::Ordering::Relaxed);
        
        if prev_count == 1 {
            // ë§ˆì§€ë§‰ ì°¸ì¡°ì´ë¯€ë¡œ ë©”ëª¨ë¦¬ í•´ì œ
            let layout = std::alloc::Layout::from_size_align(
                self.shared.original_capacity, 
                64
            ).unwrap();
            
            unsafe {
                std::alloc::dealloc(self.shared.original_ptr, layout);
            }
        }
    }
}
```

### 2. ë²¡í„°í™”ëœ I/O ì²˜ë¦¬ê¸°

```rust
// service/vectorized_io.rs
use std::io::{IoSlice, IoSliceMut};
use tokio::net::UdpSocket;

pub struct VectorizedIOProcessor {
    socket: Arc<UdpSocket>,
    send_buffers: Vec<ZeroCopyBuffer>,
    recv_buffers: Vec<ZeroCopyBuffer>,
}

impl VectorizedIOProcessor {
    /// ë°°ì¹˜ ì†¡ì‹  (ë²¡í„°í™”ëœ I/O)
    pub async fn send_batch(&mut self, messages: Vec<(&[u8], std::net::SocketAddr)>) 
        -> Result<usize, std::io::Error> 
    {
        // IoSlice ë°°ì—´ ì¤€ë¹„
        let mut io_slices = Vec::with_capacity(messages.len());
        let mut addrs = Vec::with_capacity(messages.len());
        
        for (data, addr) in messages {
            io_slices.push(IoSlice::new(data));
            addrs.push(addr);
        }
        
        // ë²¡í„°í™”ëœ ì†¡ì‹  (sendmmsg ì‹œìŠ¤í…œ ì½œ)
        let mut total_sent = 0;
        
        // í”Œë«í¼ë³„ ìµœì í™”
        #[cfg(target_os = "linux")]
        {
            total_sent = self.send_vectored_linux(&io_slices, &addrs).await?;
        }
        
        #[cfg(not(target_os = "linux"))]
        {
            // fallback: ê°œë³„ ì†¡ì‹ 
            for (slice, addr) in io_slices.iter().zip(addrs.iter()) {
                let sent = self.socket.send_to(slice, addr).await?;
                total_sent += sent;
            }
        }
        
        Ok(total_sent)
    }
    
    #[cfg(target_os = "linux")]
    async fn send_vectored_linux(&self, slices: &[IoSlice<'_>], addrs: &[std::net::SocketAddr]) 
        -> Result<usize, std::io::Error> 
    {
        // Linux sendmmsg ì‹œìŠ¤í…œ ì½œ í™œìš©
        // ì‹¤ì œ êµ¬í˜„ì€ libc ë°”ì¸ë”© í•„ìš”
        let mut total_sent = 0;
        
        // ì„ì‹œ êµ¬í˜„ - ê°œë³„ ì „ì†¡
        for (slice, addr) in slices.iter().zip(addrs.iter()) {
            let sent = self.socket.send_to(slice, addr).await?;
            total_sent += sent;
        }
        
        Ok(total_sent)
    }
    
    /// ë°°ì¹˜ ìˆ˜ì‹ 
    pub async fn recv_batch(&mut self, buffer_count: usize) 
        -> Result<Vec<(ZeroCopyBuffer, std::net::SocketAddr)>, std::io::Error> 
    {
        let mut results = Vec::with_capacity(buffer_count);
        
        // ì—¬ëŸ¬ ë²„í¼ì— ë™ì‹œ ìˆ˜ì‹ 
        for _ in 0..buffer_count {
            if let Ok(buffer) = ZeroCopyBuffer::new(1500) { // MTU í¬ê¸°
                self.recv_buffers.push(buffer);
            }
        }
        
        // ë…¼ë¸”ë¡œí‚¹ ìˆ˜ì‹  ì‹œë„
        for buffer in &mut self.recv_buffers {
            match self.socket.try_recv_from(buffer.as_mut_slice()) {
                Ok((len, addr)) => {
                    buffer.len = len;
                    // ë²„í¼ë¥¼ ê²°ê³¼ì— ì´ë™ (ì œë¡œì¹´í”¼)
                    let result_buffer = std::mem::replace(
                        buffer, 
                        ZeroCopyBuffer::new(1500).unwrap()
                    );
                    results.push((result_buffer, addr));
                }
                Err(ref e) if e.kind() == std::io::ErrorKind::WouldBlock => {
                    break; // ë” ì´ìƒ ìˆ˜ì‹ í•  ë°ì´í„° ì—†ìŒ
                }
                Err(e) => return Err(e),
            }
        }
        
        Ok(results)
    }
}
```

## ğŸ“ˆ ì ì‘í˜• í˜¼ì¡ ì œì–´

### 1. ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ê¸°ë°˜ í˜¼ì¡ ì œì–´

```rust
// service/adaptive_congestion_control.rs
use std::time::{Duration, Instant};
use std::collections::VecDeque;

pub struct AdaptiveCongestionControl {
    // í˜¼ì¡ ìœˆë„ìš° ê´€ë¦¬
    congestion_window: f64,
    ssthresh: f64,
    
    // RTT ì¶”ì 
    rtt_samples: VecDeque<Duration>,
    min_rtt: Duration,
    smoothed_rtt: Duration,
    rtt_variance: Duration,
    
    // íŒ¨í‚· ì†ì‹¤ ì¶”ì 
    lost_packets: u32,
    total_packets: u32,
    loss_rate: f64,
    
    // ìƒíƒœ
    state: CongestionState,
    last_update: Instant,
    
    // ì„¤ì •
    config: CongestionConfig,
}

#[derive(Debug, Clone, PartialEq)]
enum CongestionState {
    SlowStart,
    CongestionAvoidance,
    FastRecovery,
    NetworkProbing,
}

#[derive(Debug, Clone)]
pub struct CongestionConfig {
    pub initial_window: f64,
    pub min_window: f64,
    pub max_window: f64,
    pub alpha: f64,  // RTT í‰í™œí™” ê³„ìˆ˜
    pub beta: f64,   // í˜¼ì¡ ì‹œ ìœˆë„ìš° ê°ì†Œ ë¹„ìœ¨
    pub gamma: f64,  // ì†ì‹¤ë¥  ì„ê³„ê°’
}

impl Default for CongestionConfig {
    fn default() -> Self {
        Self {
            initial_window: 10.0,
            min_window: 2.0,
            max_window: 1000.0,
            alpha: 0.125,
            beta: 0.5,
            gamma: 0.01, // 1% ì†ì‹¤ë¥ 
        }
    }
}

impl AdaptiveCongestionControl {
    pub fn new(config: CongestionConfig) -> Self {
        Self {
            congestion_window: config.initial_window,
            ssthresh: config.max_window / 2.0,
            rtt_samples: VecDeque::with_capacity(100),
            min_rtt: Duration::from_millis(1000),
            smoothed_rtt: Duration::from_millis(100),
            rtt_variance: Duration::from_millis(50),
            lost_packets: 0,
            total_packets: 0,
            loss_rate: 0.0,
            state: CongestionState::SlowStart,
            last_update: Instant::now(),
            config,
        }
    }
    
    /// RTT ìƒ˜í”Œ ì—…ë°ì´íŠ¸
    pub fn update_rtt(&mut self, rtt: Duration) {
        self.rtt_samples.push_back(rtt);
        if self.rtt_samples.len() > 100 {
            self.rtt_samples.pop_front();
        }
        
        // ìµœì†Œ RTT ì—…ë°ì´íŠ¸
        if rtt < self.min_rtt {
            self.min_rtt = rtt;
        }
        
        // í‰í™œí™”ëœ RTT ê³„ì‚° (RFC 6298)
        if self.total_packets == 0 {
            self.smoothed_rtt = rtt;
            self.rtt_variance = rtt / 2;
        } else {
            let diff = if rtt > self.smoothed_rtt {
                rtt - self.smoothed_rtt
            } else {
                self.smoothed_rtt - rtt
            };
            
            self.rtt_variance = Duration::from_nanos(
                (self.rtt_variance.as_nanos() as f64 * (1.0 - self.config.alpha / 2.0) +
                 diff.as_nanos() as f64 * self.config.alpha / 2.0) as u64
            );
            
            self.smoothed_rtt = Duration::from_nanos(
                (self.smoothed_rtt.as_nanos() as f64 * (1.0 - self.config.alpha) +
                 rtt.as_nanos() as f64 * self.config.alpha) as u64
            );
        }
    }
    
    /// íŒ¨í‚· ì†ì‹¤ ë³´ê³ 
    pub fn report_packet_loss(&mut self, lost_count: u32) {
        self.lost_packets += lost_count;
        self.loss_rate = self.lost_packets as f64 / self.total_packets as f64;
        
        // ì†ì‹¤ë¥ ì— ë”°ë¥¸ í˜¼ì¡ ì œì–´
        if self.loss_rate > self.config.gamma {
            self.handle_congestion();
        }
    }
    
    /// í˜¼ì¡ ìƒí™© ì²˜ë¦¬
    fn handle_congestion(&mut self) {
        match self.state {
            CongestionState::SlowStart | CongestionState::CongestionAvoidance => {
                // ssthreshë¥¼ í˜„ì¬ ìœˆë„ìš°ì˜ ì ˆë°˜ìœ¼ë¡œ ì„¤ì •
                self.ssthresh = (self.congestion_window * self.config.beta).max(self.config.min_window);
                
                // ìœˆë„ìš° í¬ê¸° ê°ì†Œ
                self.congestion_window = self.ssthresh;
                
                // ë¹ ë¥¸ ë³µêµ¬ ëª¨ë“œë¡œ ì „í™˜
                self.state = CongestionState::FastRecovery;
            }
            CongestionState::FastRecovery => {
                // ì´ë¯¸ ë³µêµ¬ ëª¨ë“œì¸ ê²½ìš° ìœˆë„ìš° ì¶”ê°€ ê°ì†Œ
                self.congestion_window *= 0.8;
                self.congestion_window = self.congestion_window.max(self.config.min_window);
            }
            CongestionState::NetworkProbing => {
                // ë„¤íŠ¸ì›Œí¬ íƒì§€ ì¤‘ ì†ì‹¤ ë°œìƒ
                self.congestion_window *= 0.9;
                self.state = CongestionState::CongestionAvoidance;
            }
        }
        
        tracing::warn!(
            "í˜¼ì¡ ê°ì§€ - ìœˆë„ìš°: {:.1}, ì†ì‹¤ë¥ : {:.3}%, ìƒíƒœ: {:?}",
            self.congestion_window, self.loss_rate * 100.0, self.state
        );
    }
    
    /// ACK ìˆ˜ì‹  ì²˜ë¦¬
    pub fn on_ack_received(&mut self) {
        self.total_packets += 1;
        
        match self.state {
            CongestionState::SlowStart => {
                // ì§€ìˆ˜ì  ì¦ê°€
                self.congestion_window += 1.0;
                
                // ssthreshì— ë„ë‹¬í•˜ë©´ í˜¼ì¡ íšŒí”¼ë¡œ ì „í™˜
                if self.congestion_window >= self.ssthresh {
                    self.state = CongestionState::CongestionAvoidance;
                }
            }
            CongestionState::CongestionAvoidance => {
                // ì„ í˜• ì¦ê°€ (AIMD)
                self.congestion_window += 1.0 / self.congestion_window;
            }
            CongestionState::FastRecovery => {
                // ë¹ ë¥¸ ë³µêµ¬ì—ì„œ ì •ìƒ ìƒíƒœë¡œ ì „í™˜
                self.state = CongestionState::CongestionAvoidance;
            }
            CongestionState::NetworkProbing => {
                // ë„¤íŠ¸ì›Œí¬ ìš©ëŸ‰ íƒì§€
                self.congestion_window += 0.5;
            }
        }
        
        // ìµœëŒ€ ìœˆë„ìš° í¬ê¸° ì œí•œ
        self.congestion_window = self.congestion_window.min(self.config.max_window);
    }
    
    /// í˜„ì¬ ì „ì†¡ ê°€ëŠ¥í•œ íŒ¨í‚· ìˆ˜
    pub fn get_send_window(&self) -> usize {
        self.congestion_window as usize
    }
    
    /// ì¬ì „ì†¡ íƒ€ì„ì•„ì›ƒ ê³„ì‚°
    pub fn calculate_rto(&self) -> Duration {
        let rto = self.smoothed_rtt + 4 * self.rtt_variance;
        rto.max(Duration::from_millis(100)) // ìµœì†Œ 100ms
           .min(Duration::from_secs(60))   // ìµœëŒ€ 60ì´ˆ
    }
    
    /// ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ë³´ê³ ì„œ
    pub fn get_status_report(&self) -> String {
        format!(
            "í˜¼ì¡ ì œì–´ ìƒíƒœ:\n\
            - ìœˆë„ìš° í¬ê¸°: {:.1}\n\
            - ìƒíƒœ: {:?}\n\
            - ì†ì‹¤ë¥ : {:.3}%\n\
            - RTT: {:.1}ms (ìµœì†Œ: {:.1}ms)\n\
            - RTO: {:.1}ms",
            self.congestion_window,
            self.state,
            self.loss_rate * 100.0,
            self.smoothed_rtt.as_secs_f64() * 1000.0,
            self.min_rtt.as_secs_f64() * 1000.0,
            self.calculate_rto().as_secs_f64() * 1000.0
        )
    }
}
```

## ğŸ§  ë©”ëª¨ë¦¬ ìµœì í™” ì „ëµ

### 1. NUMA ì¸ì‹ ë©”ëª¨ë¦¬ í• ë‹¹ê¸°

```rust
// service/numa_allocator.rs
use std::sync::Arc;
use std::collections::HashMap;

pub struct NumaAwareAllocator {
    numa_nodes: Vec<NumaNode>,
    current_node: std::sync::atomic::AtomicUsize,
    allocation_policy: AllocationPolicy,
}

#[derive(Debug)]
struct NumaNode {
    node_id: usize,
    memory_pools: HashMap<usize, Vec<*mut u8>>, // size -> pool
    allocated_bytes: std::sync::atomic::AtomicU64,
    total_capacity: u64,
}

#[derive(Debug, Clone)]
pub enum AllocationPolicy {
    RoundRobin,      // ë…¸ë“œ ê°„ ìˆœí™˜ í• ë‹¹
    LocalFirst,      // ë¡œì»¬ ë…¸ë“œ ìš°ì„ 
    BalancedLoad,    // ë¶€í•˜ ê· í˜•
}

impl NumaAwareAllocator {
    /// NUMA í† í´ë¡œì§€ ê°ì§€ ë° í• ë‹¹ê¸° ì´ˆê¸°í™”
    pub fn new() -> Self {
        let numa_node_count = Self::detect_numa_nodes();
        let mut numa_nodes = Vec::with_capacity(numa_node_count);
        
        for node_id in 0..numa_node_count {
            numa_nodes.push(NumaNode {
                node_id,
                memory_pools: HashMap::new(),
                allocated_bytes: std::sync::atomic::AtomicU64::new(0),
                total_capacity: Self::get_node_memory_capacity(node_id),
            });
        }
        
        Self {
            numa_nodes,
            current_node: std::sync::atomic::AtomicUsize::new(0),
            allocation_policy: AllocationPolicy::LocalFirst,
        }
    }
    
    /// NUMA ë…¸ë“œ ìˆ˜ ê°ì§€
    fn detect_numa_nodes() -> usize {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” /sys/devices/system/node/ íŒŒì‹±
        std::env::var("NUMA_NODE_COUNT")
            .ok()
            .and_then(|s| s.parse().ok())
            .unwrap_or(1)
    }
    
    /// ë…¸ë“œë³„ ë©”ëª¨ë¦¬ ìš©ëŸ‰ ì¡°íšŒ
    fn get_node_memory_capacity(node_id: usize) -> u64 {
        // ì‹¤ì œë¡œëŠ” /proc/meminfoì™€ numa ì •ë³´ íŒŒì‹±
        1024 * 1024 * 1024 // 1GB per node (ì˜ˆì‹œ)
    }
    
    /// NUMA ì¹œí™”ì  ë©”ëª¨ë¦¬ í• ë‹¹
    pub fn allocate_on_node(&mut self, size: usize, preferred_node: Option<usize>) -> Option<*mut u8> {
        let target_node = match (preferred_node, &self.allocation_policy) {
            (Some(node), _) => node,
            (None, AllocationPolicy::RoundRobin) => {
                let node = self.current_node.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                node % self.numa_nodes.len()
            }
            (None, AllocationPolicy::LocalFirst) => {
                // í˜„ì¬ ìŠ¤ë ˆë“œê°€ ì‹¤í–‰ ì¤‘ì¸ NUMA ë…¸ë“œ ê°ì§€
                self.get_current_numa_node()
            }
            (None, AllocationPolicy::BalancedLoad) => {
                // ê°€ì¥ ë¶€í•˜ê°€ ë‚®ì€ ë…¸ë“œ ì„ íƒ
                self.get_least_loaded_node()
            }
        };
        
        self.allocate_from_node(target_node, size)
    }
    
    /// íŠ¹ì • ë…¸ë“œì—ì„œ ë©”ëª¨ë¦¬ í• ë‹¹
    fn allocate_from_node(&mut self, node_id: usize, size: usize) -> Option<*mut u8> {
        if node_id >= self.numa_nodes.len() {
            return None;
        }
        
        let node = &mut self.numa_nodes[node_id];
        
        // ì ì ˆí•œ í¬ê¸°ì˜ í’€ì—ì„œ í• ë‹¹ ì‹œë„
        let pool_size = Self::round_up_to_pool_size(size);
        
        if let Some(pool) = node.memory_pools.get_mut(&pool_size) {
            if let Some(ptr) = pool.pop() {
                node.allocated_bytes.fetch_add(size as u64, std::sync::atomic::Ordering::Relaxed);
                return Some(ptr);
            }
        }
        
        // í’€ì— ì—†ìœ¼ë©´ ìƒˆë¡œ í• ë‹¹
        self.allocate_new_block(node_id, pool_size)
    }
    
    /// ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ë¸”ë¡ í• ë‹¹
    fn allocate_new_block(&mut self, node_id: usize, size: usize) -> Option<*mut u8> {
        let layout = std::alloc::Layout::from_size_align(size, 64).ok()?;
        
        unsafe {
            // NUMA ë…¸ë“œë³„ í• ë‹¹ (Linux numa.h ë°”ì¸ë”© í•„ìš”)
            #[cfg(target_os = "linux")]
            let ptr = self.numa_alloc_on_node(layout, node_id);
            
            #[cfg(not(target_os = "linux"))]
            let ptr = std::alloc::alloc(layout);
            
            if ptr.is_null() {
                None
            } else {
                self.numa_nodes[node_id].allocated_bytes
                    .fetch_add(size as u64, std::sync::atomic::Ordering::Relaxed);
                Some(ptr)
            }
        }
    }
    
    #[cfg(target_os = "linux")]
    unsafe fn numa_alloc_on_node(&self, layout: std::alloc::Layout, node_id: usize) -> *mut u8 {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” libnuma ë°”ì¸ë”© ì‚¬ìš©
        // numa_alloc_onnode(layout.size(), node_id as i32)
        std::alloc::alloc(layout) // fallback
    }
    
    /// í’€ í¬ê¸°ë¡œ ë°˜ì˜¬ë¦¼
    fn round_up_to_pool_size(size: usize) -> usize {
        const POOL_SIZES: &[usize] = &[64, 256, 1024, 4096, 16384, 65536];
        
        POOL_SIZES.iter()
            .find(|&&pool_size| pool_size >= size)
            .copied()
            .unwrap_or(size)
    }
    
    /// í˜„ì¬ NUMA ë…¸ë“œ ID ì¡°íšŒ
    fn get_current_numa_node(&self) -> usize {
        // ì‹¤ì œë¡œëŠ” getcpu() ì‹œìŠ¤í…œ ì½œ ì‚¬ìš©
        0 // fallback
    }
    
    /// ê°€ì¥ ë¶€í•˜ê°€ ë‚®ì€ ë…¸ë“œ ì„ íƒ
    fn get_least_loaded_node(&self) -> usize {
        self.numa_nodes
            .iter()
            .enumerate()
            .min_by_key(|(_, node)| node.allocated_bytes.load(std::sync::atomic::Ordering::Relaxed))
            .map(|(idx, _)| idx)
            .unwrap_or(0)
    }
}
```

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### 1. ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì ê¸°

```rust
// service/performance_tracker.rs
use std::time::{Duration, Instant};
use std::sync::Arc;
use tokio::sync::RwLock;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetrics {
    // ì²˜ë¦¬ëŸ‰ ì§€í‘œ
    pub messages_per_second: f64,
    pub packets_per_second: f64,
    pub bytes_per_second: f64,
    
    // ì§€ì—°ì‹œê°„ ì§€í‘œ (ë§ˆì´í¬ë¡œì´ˆ)
    pub latency_avg_us: f64,
    pub latency_p50_us: f64,
    pub latency_p95_us: f64,
    pub latency_p99_us: f64,
    
    // ë©”ëª¨ë¦¬ ì§€í‘œ
    pub memory_used_mb: f64,
    pub buffer_pool_usage: f64,
    pub numa_efficiency: f64,
    
    // ë„¤íŠ¸ì›Œí¬ ì§€í‘œ
    pub packet_loss_rate: f64,
    pub retransmission_rate: f64,
    pub congestion_window: f64,
    
    // CPU ì§€í‘œ
    pub cpu_usage_percent: f64,
    pub simd_acceleration: bool,
    pub cache_hit_rate: f64,
    
    // ì‹œê°„ ì •ë³´
    pub measurement_time: std::time::SystemTime,
    pub uptime_seconds: f64,
}

pub struct PerformanceTracker {
    metrics: Arc<RwLock<PerformanceMetrics>>,
    latency_samples: Arc<RwLock<Vec<Duration>>>,
    start_time: Instant,
    
    // ì¹´ìš´í„°ë“¤
    total_messages: std::sync::atomic::AtomicU64,
    total_packets: std::sync::atomic::AtomicU64,
    total_bytes: std::sync::atomic::AtomicU64,
    
    // ìƒ˜í”Œë§ ì„¤ì •
    sample_interval: Duration,
    last_sample: std::sync::atomic::AtomicU64, // nanoseconds since epoch
}

impl PerformanceTracker {
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(RwLock::new(PerformanceMetrics {
                messages_per_second: 0.0,
                packets_per_second: 0.0,
                bytes_per_second: 0.0,
                latency_avg_us: 0.0,
                latency_p50_us: 0.0,
                latency_p95_us: 0.0,
                latency_p99_us: 0.0,
                memory_used_mb: 0.0,
                buffer_pool_usage: 0.0,
                numa_efficiency: 0.0,
                packet_loss_rate: 0.0,
                retransmission_rate: 0.0,
                congestion_window: 0.0,
                cpu_usage_percent: 0.0,
                simd_acceleration: is_x86_feature_detected!("avx2"),
                cache_hit_rate: 0.0,
                measurement_time: std::time::SystemTime::now(),
                uptime_seconds: 0.0,
            })),
            latency_samples: Arc::new(RwLock::new(Vec::with_capacity(10000))),
            start_time: Instant::now(),
            total_messages: std::sync::atomic::AtomicU64::new(0),
            total_packets: std::sync::atomic::AtomicU64::new(0),
            total_bytes: std::sync::atomic::AtomicU64::new(0),
            sample_interval: Duration::from_millis(100), // 100ms ìƒ˜í”Œë§
            last_sample: std::sync::atomic::AtomicU64::new(0),
        }
    }
    
    /// ë©”ì‹œì§€ ì²˜ë¦¬ ê¸°ë¡
    pub async fn record_message(&self, bytes: usize, latency: Duration) {
        self.total_messages.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        self.total_bytes.fetch_add(bytes as u64, std::sync::atomic::Ordering::Relaxed);
        
        // ì§€ì—°ì‹œê°„ ìƒ˜í”Œë§
        let mut samples = self.latency_samples.write().await;
        samples.push(latency);
        
        // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
        if samples.len() > 10000 {
            samples.drain(0..5000); // ì ˆë°˜ ì œê±°
        }
    }
    
    /// íŒ¨í‚· ì²˜ë¦¬ ê¸°ë¡
    pub fn record_packet(&self, bytes: usize) {
        self.total_packets.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        self.total_bytes.fetch_add(bytes as u64, std::sync::atomic::Ordering::Relaxed);
    }
    
    /// ì£¼ê¸°ì  ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    pub async fn update_metrics(&self) {
        let now = Instant::now();
        let elapsed = now.duration_since(self.start_time);
        
        let total_messages = self.total_messages.load(std::sync::atomic::Ordering::Relaxed);
        let total_packets = self.total_packets.load(std::sync::atomic::Ordering::Relaxed);
        let total_bytes = self.total_bytes.load(std::sync::atomic::Ordering::Relaxed);
        
        // ì²˜ë¦¬ëŸ‰ ê³„ì‚°
        let elapsed_secs = elapsed.as_secs_f64();
        let messages_per_second = total_messages as f64 / elapsed_secs;
        let packets_per_second = total_packets as f64 / elapsed_secs;
        let bytes_per_second = total_bytes as f64 / elapsed_secs;
        
        // ì§€ì—°ì‹œê°„ í†µê³„ ê³„ì‚°
        let latency_stats = self.calculate_latency_stats().await;
        
        // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
        let memory_stats = self.get_memory_stats();
        
        // CPU ì‚¬ìš©ë¥  ì¡°íšŒ
        let cpu_usage = self.get_cpu_usage();
        
        // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        let mut metrics = self.metrics.write().await;
        metrics.messages_per_second = messages_per_second;
        metrics.packets_per_second = packets_per_second;
        metrics.bytes_per_second = bytes_per_second;
        metrics.latency_avg_us = latency_stats.avg_us;
        metrics.latency_p50_us = latency_stats.p50_us;
        metrics.latency_p95_us = latency_stats.p95_us;
        metrics.latency_p99_us = latency_stats.p99_us;
        metrics.memory_used_mb = memory_stats.used_mb;
        metrics.buffer_pool_usage = memory_stats.pool_usage;
        metrics.cpu_usage_percent = cpu_usage;
        metrics.measurement_time = std::time::SystemTime::now();
        metrics.uptime_seconds = elapsed_secs;
    }
    
    /// ì§€ì—°ì‹œê°„ í†µê³„ ê³„ì‚°
    async fn calculate_latency_stats(&self) -> LatencyStats {
        let samples = self.latency_samples.read().await;
        
        if samples.is_empty() {
            return LatencyStats::default();
        }
        
        let mut sorted_samples: Vec<_> = samples.iter().map(|d| d.as_micros() as f64).collect();
        sorted_samples.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let avg_us = sorted_samples.iter().sum::<f64>() / sorted_samples.len() as f64;
        let p50_us = sorted_samples[sorted_samples.len() / 2];
        let p95_us = sorted_samples[sorted_samples.len() * 95 / 100];
        let p99_us = sorted_samples[sorted_samples.len() * 99 / 100];
        
        LatencyStats {
            avg_us,
            p50_us,
            p95_us,
            p99_us,
        }
    }
    
    /// ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ
    fn get_memory_stats(&self) -> MemoryStats {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” /proc/self/status íŒŒì‹±
        MemoryStats {
            used_mb: 50.0, // ì˜ˆì‹œê°’
            pool_usage: 0.7,
        }
    }
    
    /// CPU ì‚¬ìš©ë¥  ì¡°íšŒ
    fn get_cpu_usage(&self) -> f64 {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” /proc/stat íŒŒì‹±
        25.0 // ì˜ˆì‹œê°’
    }
    
    /// ì‹¤ì‹œê°„ ì„±ëŠ¥ ë³´ê³ ì„œ
    pub async fn get_performance_report(&self) -> String {
        let metrics = self.metrics.read().await;
        
        format!(
            "ğŸš€ RUDP ì„œë²„ ì„±ëŠ¥ ë³´ê³ ì„œ\n\
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\
            ğŸ“Š ì²˜ë¦¬ëŸ‰:\n\
            â€¢ ë©”ì‹œì§€/ì´ˆ: {:.1}\n\
            â€¢ íŒ¨í‚·/ì´ˆ: {:.1}\n\
            â€¢ MB/ì´ˆ: {:.2}\n\
            \n\
            â±ï¸  ì§€ì—°ì‹œê°„ (Î¼s):\n\
            â€¢ í‰ê· : {:.1}\n\
            â€¢ P50: {:.1}\n\
            â€¢ P95: {:.1}\n\
            â€¢ P99: {:.1}\n\
            \n\
            ğŸ’¾ ë©”ëª¨ë¦¬:\n\
            â€¢ ì‚¬ìš©ëŸ‰: {:.1} MB\n\
            â€¢ ë²„í¼ í’€: {:.1}%\n\
            \n\
            ğŸŒ ë„¤íŠ¸ì›Œí¬:\n\
            â€¢ íŒ¨í‚· ì†ì‹¤ë¥ : {:.3}%\n\
            â€¢ ì¬ì „ì†¡ë¥ : {:.3}%\n\
            â€¢ í˜¼ì¡ ìœˆë„ìš°: {:.1}\n\
            \n\
            ğŸ’» ì‹œìŠ¤í…œ:\n\
            â€¢ CPU: {:.1}%\n\
            â€¢ SIMD ê°€ì†: {}\n\
            â€¢ ê°€ë™ì‹œê°„: {:.1}ì´ˆ",
            metrics.messages_per_second,
            metrics.packets_per_second,
            metrics.bytes_per_second / 1_048_576.0,
            metrics.latency_avg_us,
            metrics.latency_p50_us,
            metrics.latency_p95_us,
            metrics.latency_p99_us,
            metrics.memory_used_mb,
            metrics.buffer_pool_usage * 100.0,
            metrics.packet_loss_rate * 100.0,
            metrics.retransmission_rate * 100.0,
            metrics.congestion_window,
            metrics.cpu_usage_percent,
            if metrics.simd_acceleration { "ON" } else { "OFF" },
            metrics.uptime_seconds
        )
    }
}

#[derive(Debug, Default)]
struct LatencyStats {
    avg_us: f64,
    p50_us: f64,
    p95_us: f64,
    p99_us: f64,
}

#[derive(Debug)]
struct MemoryStats {
    used_mb: f64,
    pool_usage: f64,
}
```

## ğŸ”§ í†µí•© ìµœì í™” í™œìš© ì˜ˆì‹œ

```rust
// ëª¨ë“  ìµœì í™” ê¸°ëŠ¥ì„ í†µí•©í•œ ì˜ˆì‹œ
pub async fn optimized_message_processing() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // 1. NUMA ì¸ì‹ ë©”ëª¨ë¦¬ í• ë‹¹ê¸° ì´ˆê¸°í™”
    let numa_allocator = Arc::new(Mutex::new(NumaAwareAllocator::new()));
    
    // 2. SIMD íŒ¨í‚· í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    let simd_processor = SimdPacketProcessor::new();
    
    // 3. ì œë¡œì¹´í”¼ I/O í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    let mut vectorized_io = VectorizedIOProcessor::new().await?;
    
    // 4. ì ì‘í˜• í˜¼ì¡ ì œì–´ ì´ˆê¸°í™”
    let mut congestion_control = AdaptiveCongestionControl::new(CongestionConfig::default());
    
    // 5. ì„±ëŠ¥ ì¶”ì ê¸° ì´ˆê¸°í™”
    let performance_tracker = Arc::new(PerformanceTracker::new());
    
    // ë©”ì‹œì§€ ì²˜ë¦¬ ë£¨í”„
    loop {
        let start_time = Instant::now();
        
        // ë°°ì¹˜ ìˆ˜ì‹  (ì œë¡œì¹´í”¼)
        let received_packets = vectorized_io.recv_batch(32).await?;
        
        if received_packets.is_empty() {
            tokio::time::sleep(Duration::from_micros(100)).await;
            continue;
        }
        
        // SIMD ìµœì í™”ëœ íŒ¨í‚· ì²˜ë¦¬
        let processed_packets = simd_processor.process_packet_batch(&received_packets).await?;
        
        // í˜¼ì¡ ì œì–´ ì—…ë°ì´íŠ¸
        for packet in &processed_packets {
            congestion_control.update_rtt(start_time.elapsed());
        }
        
        // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
        let processing_latency = start_time.elapsed();
        performance_tracker.record_message(1024, processing_latency).await;
        
        // ì£¼ê¸°ì  ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥
        if rand::random::<f32>() < 0.01 { // 1% í™•ë¥ 
            let report = performance_tracker.get_performance_report().await;
            tracing::info!("\n{}", report);
        }
    }
}
```

ì´ ê°€ì´ë“œëŠ” RUDP ì„œë²„ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•œ ê³ ê¸‰ ìµœì í™” ê¸°ë²•ë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤. SIMD í•˜ë“œì›¨ì–´ ê°€ì†, ì œë¡œì¹´í”¼ I/O, ì ì‘í˜• í˜¼ì¡ ì œì–´, NUMA ì¸ì‹ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë“±ì„ í†µí•´ ëª©í‘œì¸ 20,000+ msg/sec ì²˜ë¦¬ëŸ‰ê³¼ <0.5ms ì§€ì—°ì‹œê°„ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.