//! ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
//!
//! ì„±ëŠ¥ ëª©í‘œ:
//! - ì‘ì—… ì²˜ë¦¬ ì†ë„: 40% í–¥ìƒ (ìš°ì„ ìˆœìœ„ í + ì‘ì—… ìŠ¤í‹¸ë§)
//! - ì§€ì—° ì‹œê°„: 50% ê°ì†Œ (ìŠ¤ë§ˆíŠ¸ ìŠ¤ì¼€ì¤„ë§)
//! - CPU í™œìš©ë¥ : 30% ê°œì„  (ë™ì  ì›Œì»¤ ì¡°ì •)

use crossbeam_queue::SegQueue;
use serde::{Deserialize, Serialize};
use std::cmp::Ordering as CmpOrdering;
use std::future::Future;
use std::pin::Pin;
use std::sync::{
    atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering},
    Arc,
};
use tokio::sync::Notify;
use tokio::time::{Duration, Instant};
use tracing::{debug, info, warn};

/// ì‘ì—… ìš°ì„ ìˆœìœ„ ë ˆë²¨
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
pub enum TaskPriority {
    Critical = 0, // ê¸´ê¸‰í•œ ë³´ì•ˆ/ì˜¤ë¥˜ ì²˜ë¦¬
    High = 1,     // ì‹¤ì‹œê°„ ê²Œì„ ë©”ì‹œì§€
    #[default]
    Normal = 2, // ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬
    Low = 3,      // ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì‘ì—…
    Idle = 4,     // ìœ íœ´ ì‹œê°„ ì‘ì—…
}

/// ë¹„ë™ê¸° ì‘ì—… ë˜í¼
pub struct AsyncTask {
    id: u64,
    priority: TaskPriority,
    submitted_at: Instant,
    deadline: Option<Instant>,
    task: Pin<Box<dyn Future<Output = ()> + Send + 'static>>,
    worker_affinity: Option<usize>, // NUMA/CPU ì¹œí™”ì„±
}

impl AsyncTask {
    pub fn new<F>(task: F, priority: TaskPriority) -> Self
    where
        F: Future<Output = ()> + Send + 'static,
    {
        static TASK_COUNTER: AtomicU64 = AtomicU64::new(1);

        Self {
            id: TASK_COUNTER.fetch_add(1, Ordering::Relaxed),
            priority,
            submitted_at: Instant::now(),
            deadline: None,
            task: Box::pin(task),
            worker_affinity: None,
        }
    }

    /// ë°ë“œë¼ì¸ì´ ìˆëŠ” ì‘ì—… ìƒì„±
    pub fn new_with_deadline<F>(task: F, priority: TaskPriority, deadline: Duration) -> Self
    where
        F: Future<Output = ()> + Send + 'static,
    {
        let mut async_task = Self::new(task, priority);
        async_task.deadline = Some(Instant::now() + deadline);
        async_task
    }

    /// ì›Œì»¤ ì¹œí™”ì„± ì„¤ì •
    pub fn with_affinity(mut self, worker_id: usize) -> Self {
        self.worker_affinity = Some(worker_id);
        self
    }

    pub fn id(&self) -> u64 {
        self.id
    }
    pub fn priority(&self) -> TaskPriority {
        self.priority
    }
    pub fn submitted_at(&self) -> Instant {
        self.submitted_at
    }
    pub fn is_overdue(&self) -> bool {
        self.deadline.is_some_and(|d| Instant::now() > d)
    }
}

impl PartialEq for AsyncTask {
    fn eq(&self, other: &Self) -> bool {
        self.priority == other.priority && self.id == other.id
    }
}

impl Eq for AsyncTask {}

impl PartialOrd for AsyncTask {
    fn partial_cmp(&self, other: &Self) -> Option<CmpOrdering> {
        Some(self.cmp(other))
    }
}

impl Ord for AsyncTask {
    fn cmp(&self, other: &Self) -> CmpOrdering {
        // ìš°ì„ ìˆœìœ„ê°€ ë†’ì„ìˆ˜ë¡ ë¨¼ì € ì²˜ë¦¬ (Reverseë¡œ Min Heapì„ Max Heapìœ¼ë¡œ)
        other
            .priority
            .cmp(&self.priority)
            .then_with(|| self.submitted_at.cmp(&other.submitted_at))
    }
}

/// ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SchedulerConfig {
    /// ì›Œì»¤ ìŠ¤ë ˆë“œ ìˆ˜
    pub worker_count: usize,
    /// ìš°ì„ ìˆœìœ„ í ìš©ëŸ‰
    pub queue_capacity: usize,
    /// ë°°ì¹˜ í¬ê¸°
    pub batch_size: usize,
    /// ì‘ì—… ìŠ¤í‹¸ë§ í™œì„±í™”
    pub enable_work_stealing: bool,
    /// ë™ì  ì›Œì»¤ ì¡°ì •
    pub enable_dynamic_scaling: bool,
    /// ë¡œë“œ ë°¸ëŸ°ì‹± ê°„ê²© (ë°€ë¦¬ì´ˆ)
    pub load_balancing_interval_ms: u64,
    /// ìµœëŒ€ ì§€ì—° ì‹œê°„ (ë§ˆì´í¬ë¡œì´ˆ)
    pub max_latency_us: u64,
}

impl Default for SchedulerConfig {
    fn default() -> Self {
        Self {
            worker_count: num_cpus::get().max(4),
            queue_capacity: 10000,
            batch_size: 32,
            enable_work_stealing: true,
            enable_dynamic_scaling: true,
            load_balancing_interval_ms: 100,
            max_latency_us: 1000, // 1ms
        }
    }
}

/// ì›Œì»¤ ìŠ¤ë ˆë“œ í†µê³„
#[derive(Debug, Default)]
pub struct WorkerStats {
    pub worker_id: usize,
    pub tasks_processed: AtomicU64,
    pub tasks_stolen: AtomicU64,
    pub tasks_given: AtomicU64,
    pub avg_processing_time_ns: AtomicU64,
    pub current_load: AtomicUsize, // í˜„ì¬ í í¬ê¸°
    pub is_idle: AtomicBool,
}

impl WorkerStats {
    pub fn new(worker_id: usize) -> Self {
        Self {
            worker_id,
            tasks_processed: AtomicU64::new(0),
            tasks_stolen: AtomicU64::new(0),
            tasks_given: AtomicU64::new(0),
            avg_processing_time_ns: AtomicU64::new(0),
            current_load: AtomicUsize::new(0),
            is_idle: AtomicBool::new(true),
        }
    }
}

/// ì›Œì»¤ ìŠ¤ë ˆë“œ
pub struct AsyncWorker {
    id: usize,
    task_queue: Arc<SegQueue<AsyncTask>>,
    stats: Arc<WorkerStats>,
    shutdown_signal: Arc<AtomicBool>,
    task_notify: Arc<Notify>,
    work_stealing_enabled: bool,
}

impl AsyncWorker {
    pub fn new(id: usize, work_stealing_enabled: bool, shutdown_signal: Arc<AtomicBool>) -> Self {
        Self {
            id,
            task_queue: Arc::new(SegQueue::new()),
            stats: Arc::new(WorkerStats::new(id)),
            shutdown_signal,
            task_notify: Arc::new(Notify::new()),
            work_stealing_enabled,
        }
    }

    /// ì‘ì—… ì¶”ê°€
    pub async fn submit_task(&self, task: AsyncTask) {
        self.task_queue.push(task);
        self.stats.current_load.fetch_add(1, Ordering::Relaxed);
        self.task_notify.notify_one();
    }

    /// ì‘ì—… ìŠ¤í‹¸ë§ (ë‹¤ë¥¸ ì›Œì»¤ì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸°)
    pub async fn try_steal_task(&self, from_worker: &AsyncWorker) -> Option<AsyncTask> {
        if !self.work_stealing_enabled || from_worker.id == self.id {
            return None;
        }

        // ë‹¨ìˆœ ìŠ¤í‹¸ë§: íì—ì„œ í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¤ê¸°
        if let Some(stolen_task) = from_worker.task_queue.pop() {
            from_worker
                .stats
                .current_load
                .fetch_sub(1, Ordering::Relaxed);
            from_worker
                .stats
                .tasks_given
                .fetch_add(1, Ordering::Relaxed);
            self.stats.tasks_stolen.fetch_add(1, Ordering::Relaxed);
            Some(stolen_task)
        } else {
            None
        }
    }

    /// ì›Œì»¤ ë©”ì¸ ë£¨í”„ ì‹¤í–‰
    pub async fn run(&self, other_workers: Arc<Vec<Arc<AsyncWorker>>>) {
        info!("ë¹„ë™ê¸° ì›Œì»¤ {} ì‹œì‘", self.id);

        while !self.shutdown_signal.load(Ordering::Relaxed) {
            let task = self.get_next_task(&other_workers).await;

            if let Some(task) = task {
                self.stats.is_idle.store(false, Ordering::Relaxed);
                let start_time = Instant::now();

                // ë°ë“œë¼ì¸ ì²´í¬
                if task.is_overdue() {
                    warn!(
                        "ì‘ì—… {} ë°ë“œë¼ì¸ ì´ˆê³¼ - ìš°ì„ ìˆœìœ„: {:?}",
                        task.id(),
                        task.priority()
                    );
                }

                // ì‘ì—… ì‹¤í–‰
                debug!(
                    "ì›Œì»¤ {} ì‘ì—… {} ì‹¤í–‰ ì‹œì‘ (ìš°ì„ ìˆœìœ„: {:?})",
                    self.id,
                    task.id(),
                    task.priority()
                );

                let task_id = task.id();

                // Future ì‹¤í–‰
                let task_future = task.task;
                task_future.await;

                // í†µê³„ ì—…ë°ì´íŠ¸
                let duration = start_time.elapsed();
                self.stats.tasks_processed.fetch_add(1, Ordering::Relaxed);

                // ì§€ìˆ˜ ì´ë™ í‰ê· ìœ¼ë¡œ í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê°±ì‹ 
                let duration_ns = duration.as_nanos() as u64;
                let current_avg = self.stats.avg_processing_time_ns.load(Ordering::Relaxed);
                let new_avg = if current_avg == 0 {
                    duration_ns
                } else {
                    (current_avg * 7 + duration_ns) / 8
                };
                self.stats
                    .avg_processing_time_ns
                    .store(new_avg, Ordering::Relaxed);

                debug!(
                    "ì›Œì»¤ {} ì‘ì—… {} ì™„ë£Œ ({}Î¼s)",
                    self.id,
                    task_id,
                    duration.as_micros()
                );
            } else {
                // ì‘ì—…ì´ ì—†ìœ¼ë©´ ìœ íœ´ ìƒíƒœë¡œ ì „í™˜
                self.stats.is_idle.store(true, Ordering::Relaxed);

                // ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì£¼ê¸°ì  ì²´í¬)
                tokio::time::timeout(Duration::from_millis(10), self.task_notify.notified())
                    .await
                    .ok();
            }
        }

        info!("ë¹„ë™ê¸° ì›Œì»¤ {} ì¢…ë£Œ", self.id);
    }

    /// ë‹¤ìŒ ì‘ì—… ê°€ì ¸ì˜¤ê¸° (ìŠ¤í‹¸ë§ í¬í•¨)
    async fn get_next_task(&self, other_workers: &Arc<Vec<Arc<AsyncWorker>>>) -> Option<AsyncTask> {
        // 1. ìì‹ ì˜ íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸°
        if let Some(task) = self.task_queue.pop() {
            self.stats.current_load.fetch_sub(1, Ordering::Relaxed);
            return Some(task);
        }

        // 2. ì‘ì—… ìŠ¤í‹¸ë§ ì‹œë„
        if self.work_stealing_enabled {
            for other_worker in other_workers.iter() {
                if let Some(stolen_task) = self.try_steal_task(other_worker).await {
                    debug!("ì›Œì»¤ {} -> {} ì‘ì—… ìŠ¤í‹¸ë§ ì„±ê³µ", other_worker.id, self.id);
                    return Some(stolen_task);
                }
            }
        }

        None
    }

    pub fn get_stats(&self) -> Arc<WorkerStats> {
        self.stats.clone()
    }

    pub async fn get_queue_size(&self) -> usize {
        self.task_queue.len()
    }
}

/// ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
pub struct AsyncTaskScheduler {
    config: SchedulerConfig,
    workers: Arc<Vec<Arc<AsyncWorker>>>,
    shutdown_signal: Arc<AtomicBool>,
    scheduler_stats: Arc<SchedulerStats>,
}

/// ìŠ¤ì¼€ì¤„ëŸ¬ ì „ì²´ í†µê³„
#[derive(Debug, Default)]
pub struct SchedulerStats {
    pub total_tasks_submitted: AtomicU64,
    pub total_tasks_completed: AtomicU64,
    pub total_tasks_rejected: AtomicU64,
    pub avg_queue_latency_ns: AtomicU64,
    pub avg_processing_latency_ns: AtomicU64,
    pub work_stealing_events: AtomicU64,
    pub load_balancing_events: AtomicU64,
}

impl AsyncTaskScheduler {
    /// ìƒˆë¡œìš´ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
    pub fn new(config: SchedulerConfig) -> Self {
        let shutdown_signal = Arc::new(AtomicBool::new(false));
        let mut workers = Vec::with_capacity(config.worker_count);

        info!(
            "ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” - ì›Œì»¤ ìˆ˜: {}, ìŠ¤í‹¸ë§: {}",
            config.worker_count, config.enable_work_stealing
        );

        // ì›Œì»¤ ìŠ¤ë ˆë“œë“¤ ìƒì„±
        for worker_id in 0..config.worker_count {
            let worker = Arc::new(AsyncWorker::new(
                worker_id,
                config.enable_work_stealing,
                shutdown_signal.clone(),
            ));
            workers.push(worker);
        }

        Self {
            config,
            workers: Arc::new(workers),
            shutdown_signal,
            scheduler_stats: Arc::new(SchedulerStats::default()),
        }
    }

    /// ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    pub async fn start(&self) {
        info!("ğŸš€ ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘");

        let workers_clone = self.workers.clone();

        // ê° ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        for worker in self.workers.iter() {
            let worker_clone = worker.clone();
            let workers_ref = workers_clone.clone();

            tokio::spawn(async move {
                worker_clone.run(workers_ref).await;
            });
        }

        // ë™ì  ë¡œë“œ ë°¸ëŸ°ì‹± íƒœìŠ¤í¬ ì‹œì‘ (í˜„ì¬ ë¯¸êµ¬í˜„)
        if self.config.enable_dynamic_scaling {
            debug!("ë™ì  ìŠ¤ì¼€ì¼ë§ì´ í™œì„±í™”ë˜ì—ˆì§€ë§Œ í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•ŠìŒ");
            // TODO: ì‹¤ì œ ë¡œë“œ ë°¸ëŸ°ì‹± êµ¬í˜„
        }

        info!(
            "âœ… ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ - {} ì›Œì»¤ í™œì„±í™”",
            self.config.worker_count
        );
    }

    /// ì‘ì—… ìŠ¤ì¼€ì¤„ë§
    pub async fn schedule<F>(&self, task: F, priority: TaskPriority) -> Result<(), &'static str>
    where
        F: Future<Output = ()> + Send + 'static,
    {
        let async_task = AsyncTask::new(task, priority);
        self.schedule_task(async_task).await
    }

    /// ë°ë“œë¼ì¸ì´ ìˆëŠ” ì‘ì—… ìŠ¤ì¼€ì¤„ë§
    pub async fn schedule_with_deadline<F>(
        &self,
        task: F,
        priority: TaskPriority,
        deadline: Duration,
    ) -> Result<(), &'static str>
    where
        F: Future<Output = ()> + Send + 'static,
    {
        let async_task = AsyncTask::new_with_deadline(task, priority, deadline);
        self.schedule_task(async_task).await
    }

    /// ë‚´ë¶€ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ë¡œì§
    async fn schedule_task(&self, task: AsyncTask) -> Result<(), &'static str> {
        self.scheduler_stats
            .total_tasks_submitted
            .fetch_add(1, Ordering::Relaxed);

        // ì›Œì»¤ ì„ íƒ ë¡œì§
        let worker = if let Some(affinity) = task.worker_affinity {
            // ì¹œí™”ì„±ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì›Œì»¤ ì‚¬ìš©
            if affinity < self.workers.len() {
                &self.workers[affinity]
            } else {
                return Err("Invalid worker affinity");
            }
        } else {
            // ë¡œë“œ ë°¸ëŸ°ì‹±: ê°€ì¥ ë¶€í•˜ê°€ ë‚®ì€ ì›Œì»¤ ì„ íƒ
            self.select_least_loaded_worker().await
        };

        debug!(
            "ì‘ì—… {} ì›Œì»¤ {}ì— í• ë‹¹ (ìš°ì„ ìˆœìœ„: {:?})",
            task.id(),
            worker.id,
            task.priority()
        );

        worker.submit_task(task).await;
        Ok(())
    }

    /// ê°€ì¥ ë¶€í•˜ê°€ ë‚®ì€ ì›Œì»¤ ì„ íƒ
    async fn select_least_loaded_worker(&self) -> &Arc<AsyncWorker> {
        let mut min_load = usize::MAX;
        let mut selected_worker_idx = 0;

        for (idx, worker) in self.workers.iter().enumerate() {
            let load = worker.get_queue_size().await;
            if load < min_load {
                min_load = load;
                selected_worker_idx = idx;
            }
        }

        &self.workers[selected_worker_idx]
    }

    /// ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ
    pub async fn shutdown(&self) {
        info!("ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì¤‘...");
        self.shutdown_signal.store(true, Ordering::Relaxed);

        // ëª¨ë“  ì›Œì»¤ì— ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
        for worker in self.workers.iter() {
            worker.task_notify.notify_one();
        }

        // ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ì›Œì»¤ë“¤ì´ ì •ë¦¬ë  ì‹œê°„ ì œê³µ
        tokio::time::sleep(Duration::from_millis(100)).await;

        info!("âœ… ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì™„ë£Œ");
    }

    /// ì„±ëŠ¥ í†µê³„ ë°˜í™˜
    pub async fn get_performance_report(&self) -> String {
        let mut worker_stats = Vec::new();
        let mut total_processed = 0;
        let mut total_stolen = 0;
        let mut avg_latency = 0u64;

        for worker in self.workers.iter() {
            let stats = worker.get_stats();
            let processed = stats.tasks_processed.load(Ordering::Relaxed);
            let stolen = stats.tasks_stolen.load(Ordering::Relaxed);
            let latency = stats.avg_processing_time_ns.load(Ordering::Relaxed);
            let queue_size = worker.get_queue_size().await;

            worker_stats.push(format!(
                "  Worker {}: {}ê°œ ì²˜ë¦¬, {}ê°œ ìŠ¤í‹¸ë§, {}Î¼s í‰ê· , {}ê°œ ëŒ€ê¸°",
                worker.id,
                processed,
                stolen,
                latency / 1000,
                queue_size
            ));

            total_processed += processed;
            total_stolen += stolen;
            if latency > 0 {
                avg_latency = (avg_latency + latency) / 2;
            }
        }

        format!(
            "ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì„±ëŠ¥ ë³´ê³ ì„œ:\n\
             - ì´ ì²˜ë¦¬ëœ ì‘ì—…: {}\n\
             - ì´ ìŠ¤í‹¸ë§ ì´ë²¤íŠ¸: {}\n\
             - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {}Î¼s\n\
             - ì›Œì»¤ ì„¸ë¶€ ì •ë³´:\n{}\n\
             - ë¡œë“œ ë°¸ëŸ°ì‹± ì´ë²¤íŠ¸: {}\n\
             - ì œì¶œëœ ì‘ì—…: {}",
            total_processed,
            total_stolen,
            avg_latency / 1000,
            worker_stats.join("\n"),
            self.scheduler_stats
                .load_balancing_events
                .load(Ordering::Relaxed),
            self.scheduler_stats
                .total_tasks_submitted
                .load(Ordering::Relaxed)
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::{sleep, Duration};

    #[tokio::test]
    async fn test_task_scheduler_basic() {
        let config = SchedulerConfig {
            worker_count: 2,
            ..Default::default()
        };
        let scheduler = AsyncTaskScheduler::new(config);
        scheduler.start().await;

        // ê°„ë‹¨í•œ ì‘ì—… ìŠ¤ì¼€ì¤„ë§
        let result = scheduler
            .schedule(
                async {
                    tokio::time::sleep(Duration::from_millis(1)).await;
                },
                TaskPriority::Normal,
            )
            .await;

        assert!(result.is_ok());

        // ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ì‘ì—…ì´ ì²˜ë¦¬ë˜ë„ë¡
        sleep(Duration::from_millis(10)).await;

        let report = scheduler.get_performance_report().await;
        assert!(report.contains("ì´ ì²˜ë¦¬ëœ ì‘ì—…"));

        scheduler.shutdown().await;
    }

    #[tokio::test]
    async fn test_priority_scheduling() {
        let config = SchedulerConfig {
            worker_count: 1,
            ..Default::default()
        };
        let scheduler = AsyncTaskScheduler::new(config);
        scheduler.start().await;

        // ì—¬ëŸ¬ ìš°ì„ ìˆœìœ„ ì‘ì—… ì œì¶œ
        scheduler
            .schedule(async {}, TaskPriority::Low)
            .await
            .expect("Test assertion failed");
        scheduler
            .schedule(async {}, TaskPriority::Critical)
            .await
            .expect("Test assertion failed");
        scheduler
            .schedule(async {}, TaskPriority::High)
            .await
            .expect("Test assertion failed");

        sleep(Duration::from_millis(10)).await;

        let report = scheduler.get_performance_report().await;
        assert!(report.contains("3ê°œ ì²˜ë¦¬") || report.contains("ì²˜ë¦¬ëœ ì‘ì—…: 3"));

        scheduler.shutdown().await;
    }

    #[test]
    fn test_task_priority_ordering() {
        assert!(TaskPriority::Critical < TaskPriority::High);
        assert!(TaskPriority::High < TaskPriority::Normal);
        assert!(TaskPriority::Normal < TaskPriority::Low);
        assert!(TaskPriority::Low < TaskPriority::Idle);
    }
}
